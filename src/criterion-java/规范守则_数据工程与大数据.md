# 规范守则 - 数据工程与大数据

## 项目类型
- 批处理/流处理管道、数据湖入湖任务、实时分析、机器学习预处理
- 技术栈：Apache Spark、Apache Flink、Kafka Streams、Beam、Hadoop 生态、Iceberg/Hudi/Delta Lake

## 数据治理与版本化
- 按数据生命周期划分`raw / staged / curated`目录，使用Hive Metastore或Lakehouse目录统一治理。
- 使用 [Apache Atlas](https://atlas.apache.org/) 或 Data Catalog 管理血缘与元数据。
- 数据版本管理：DVC、LakeFS、Delta Time Travel；记录Schema演进策略（Avro Schema Registry）。
- 隐私与合规：在ETL中执行脱敏/掩码策略，遵守所在地区数据法规。

## 管道设计
- Spark/Flink 作业统一封装在`pipeline`模块，编码时避免 driver-side collect。
- 遵循Databricks/Spark性能指南：
  - 分区对齐、广播Join限制在小数据集。
  - 避免在UDF中执行长耗时IO，优先使用内置函数。
  - 调整并行度与shuffle分区，使用Adaptive Query Execution。
- 通过事件驱动工作流（Airflow、Argo、Dagster）调度，定义重试与回滚策略。

## 项目结构示例（Spark + Gradle）
```
data-pipeline/
├── build.gradle.kts
├── src/main/java/
│   ├── pipelines/BatchIngestion.java
│   ├── pipelines/RealtimeJob.java
│   └── utils/MetricEmitter.java
├── src/main/resources/
│   └── application.conf
├── src/test/java/
│   └── pipelines/BatchIngestionTest.java
└── dags/
    └── airflow_batch_ingestion.py
```

## 测试与验证
- 单元测试：使用 `spark-testing-base` 或 `Flink Test Harness` 构造本地集群。
- 统计验证：在CI中执行分布漂移（KS检验、PSI）与业务对账。
- 数据质量：内置 Great Expectations / Deequ 校验规则。
- 性能基线：Spark `spark-submit --dry-run` + Databricks Ganglia/CloudWatch 指标；Flink 监控Backpressure与Checkpoint耗时。

## 运维与成本控制
- 监控：收集作业时延、吞吐、失败率、GC、Shuffle spill等指标；根据指标调整集群资源。
- 成本策略：自动弹性扩缩容、Spot实例策略及任务优先级排程。
- 容灾：在Flink中启用Exactly-Once Checkpoint + Savepoint；Spark Structured Streaming启用Checkpoint与Idempotent Sink。

## 参考资料
- [Databricks: Top 10 Spark Performance Mistakes](https://community.databricks.com/t5/technical-blog/top-10-code-mistakes-that-degrade-your-spark-performance/ba-p/118468)
- [Apache Spark 官方文档](https://spark.apache.org/docs/latest/) – Job调优与配置
- [Apache Flink Documentation](https://nightlies.apache.org/flink/flink-docs-release-1.19/) – 流计算最佳实践
- [Google Cloud Dataflow (Apache Beam)](https://cloud.google.com/dataflow/docs) – 可移植流水线模式
- [Effective Java](https://www.javaguides.net/2025/02/effective-java-15-best-practices.html) – 集合、并发与资源管理原则
